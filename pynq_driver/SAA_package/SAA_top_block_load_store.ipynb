{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAA_top测试\n",
    "## 1. 加载Overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original matrix:\n",
      "[[  0   1   2   3   4   5   6   7   8   9  10]\n",
      " [ 11  12  13  14  15  16  17  18  19  20  21]\n",
      " [ 22  23  24  25  26  27  28  29  30  31  32]\n",
      " [ 33  34  35  36  37  38  39  40  41  42  43]\n",
      " [ 44  45  46  47  48  49  50  51  52  53  54]\n",
      " [ 55  56  57  58  59  60  61  62  63  64  65]\n",
      " [ 66  67  68  69  70  71  72  73  74  75  76]\n",
      " [ 77  78  79  80  81  82  83  84  85  86  87]\n",
      " [ 88  89  90  91  92  93  94  95  96  97  98]\n",
      " [ 99 100 101 102 103 104 105 106 107 108 109]\n",
      " [110 111 112 113 114 115 116 117 118 119 120]]\n",
      "Padded matrix:\n",
      "[[  0   1   2   3   4   5   6   7   8   9  10   0]\n",
      " [ 11  12  13  14  15  16  17  18  19  20  21   0]\n",
      " [ 22  23  24  25  26  27  28  29  30  31  32   0]\n",
      " [ 33  34  35  36  37  38  39  40  41  42  43   0]\n",
      " [ 44  45  46  47  48  49  50  51  52  53  54   0]\n",
      " [ 55  56  57  58  59  60  61  62  63  64  65   0]\n",
      " [ 66  67  68  69  70  71  72  73  74  75  76   0]\n",
      " [ 77  78  79  80  81  82  83  84  85  86  87   0]\n",
      " [ 88  89  90  91  92  93  94  95  96  97  98   0]\n",
      " [ 99 100 101 102 103 104 105 106 107 108 109   0]\n",
      " [110 111 112 113 114 115 116 117 118 119 120   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "Buffer content (flattened):\n",
      "[  0   1   2   3  11  12  13  14  22  23  24  25  33  34  35  36   4   5\n",
      "   6   7  15  16  17  18  26  27  28  29  37  38  39  40   8   9  10   0\n",
      "  19  20  21   0  30  31  32   0  41  42  43   0  44  45  46  47  55  56\n",
      "  57  58  66  67  68  69  77  78  79  80  48  49  50  51  59  60  61  62\n",
      "  70  71  72  73  81  82  83  84  52  53  54   0  63  64  65   0  74  75\n",
      "  76   0  85  86  87   0  88  89  90  91  99 100 101 102 110 111 112 113\n",
      "   0   0   0   0  92  93  94  95 103 104 105 106 114 115 116 117   0   0\n",
      "   0   0  96  97  98   0 107 108 109   0 118 119 120   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pynq import allocate\n",
    "\n",
    "# 假设矩阵和块的大小\n",
    "matrix_rows, matrix_cols = 11, 11  # 矩阵大小，这次尝试一个不能整除的情况\n",
    "block_size = 4  # 块大小为 2x2\n",
    "\n",
    "# 创建一个示例矩阵\n",
    "matrix = np.arange(matrix_rows * matrix_cols).reshape(matrix_rows, matrix_cols)\n",
    "print(\"Original matrix:\")\n",
    "print(matrix)\n",
    "\n",
    "# 计算填充后的新大小\n",
    "new_rows = matrix_rows + (block_size - matrix_rows % block_size) % block_size\n",
    "new_cols = matrix_cols + (block_size - matrix_cols % block_size) % block_size\n",
    "\n",
    "# 创建填充后的矩阵\n",
    "padded_matrix = np.zeros((new_rows, new_cols), dtype=matrix.dtype)\n",
    "padded_matrix[:matrix_rows, :matrix_cols] = matrix  # 将原矩阵复制到填充矩阵中\n",
    "print(\"Padded matrix:\")\n",
    "print(padded_matrix)\n",
    "\n",
    "# 分配连续缓冲区，这次根据填充后的尺寸来分配\n",
    "buffer_size = new_rows * new_cols  # 缓冲区大小等于填充后矩阵的元素个数\n",
    "buffer = allocate(shape=(buffer_size,), dtype=np.int32)\n",
    "\n",
    "# 矩阵按块大小分割并打包到缓冲区\n",
    "def pack_matrix_to_buffer(matrix, block_size, buffer):\n",
    "    rows, cols = matrix.shape\n",
    "    buffer_index = 0\n",
    "    for block_row in range(0, rows, block_size):\n",
    "        for block_col in range(0, cols, block_size):\n",
    "            # 提取块数据，使用np.pad确保块的大小为block_size x block_size\n",
    "            block = matrix[block_row:block_row+block_size, block_col:block_col+block_size]\n",
    "            if block.shape[0] < block_size or block.shape[1] < block_size:\n",
    "                # 如果块小于block_size，使用0填充。\n",
    "                block = np.pad(block, ((0, block_size-block.shape[0]), (0, block_size-block.shape[1])), 'constant')\n",
    "            buffer[buffer_index:buffer_index+block.size] = block.flatten() #二维块降到一维填充\n",
    "            buffer_index += block.size\n",
    "\n",
    "# 执行打包操作\n",
    "pack_matrix_to_buffer(padded_matrix, block_size, buffer)\n",
    "\n",
    "# 将连续缓冲区的内容打印出来，以验证结果\n",
    "print(\"Buffer content (flattened):\")\n",
    "print(buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 加载Overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saa_top Overlay downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pynq import allocate\n",
    "import random\n",
    "import time\n",
    "import saa_top_driver\n",
    "from saa_insn_driver import * \n",
    "from saa_utils import * \n",
    "# 创建 SaaDriver 实例\n",
    "saa_driver = saa_top_driver.SaaDriver(\"saa_top.bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.连续缓存申请"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义指令缓冲区大小\n",
    "insn_count = 4000 # 最多能容纳2000条指令\n",
    "block_size = 2*MATRIX_WIDTH # 以脉动阵列大小作为分块\n",
    "# 定义buffer大小,这是执行一个批量的大小\n",
    "row =  6*MATRIX_WIDTH\n",
    "col =  6*MATRIX_WIDTH\n",
    "col1 = 6*MATRIX_WIDTH\n",
    "\n",
    "# 定义PS端缓冲区,不使用cache，数据类型注意\n",
    "# instruct_buffer = allocate(shape = (insn_count), cacheable = 0, dtype = Instruct_DataType)\n",
    "input_buffer = allocate(shape = (row*col), cacheable = 0, dtype = Input_DataType)\n",
    "weight_buffer = allocate(shape = (col*col1), cacheable = 0, dtype = Weight_DataType)\n",
    "bias_buffer  = allocate(shape = (row*col1), cacheable = 0, dtype = Output_DataType)\n",
    "output_buffer  = allocate(shape = (row*col1), cacheable = 0, dtype = Output_DataType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.测试数据生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly generated input buffer:\n",
      "[[40 92 29 15 10 97 47 25 35  6 72 22 46 54 12 43 30 82 73 75  4 24 57 29]\n",
      " [ 7 45 14 82 34 82 16 84 49  1  8 39 95 90 99 52 75 42 50 85 10  8 30 47]\n",
      " [20 53 30 63 43 54 76 31 52 90 74 78 68 20 25 33 32  2 31 78 81 37 91  7]\n",
      " [39 74 90 46 67 84 34 52 33  4 91  3 42 83 56 22 55 47 51 80 65 56 57 11]\n",
      " [73 38 44 66 31 30 90 33 62 84 11 58 78  6 83 69 64 56 88 67 93 78 45 69]\n",
      " [37 99 20 88 84 57 68 78 87  1 46  9 76 70 29 54 16 95 69 49 73 83 25 88]\n",
      " [62 29 31 64 54 24 66 41  5 46 80 14 13 32 52 70  9 76 68 24 76 85 16 50]\n",
      " [91 57  4 48 74 56 90 74 96 27 63 77 68 79 56 49 74 19 39 55 14 89 42 46]\n",
      " [64  8 26 18 94 50 37 51 49 35 15 39 42  7 75  8 49 87  1 62 41 17 11 99]\n",
      " [22  3 28 82 43 75 40 39 20 73 14 22 30 57 12 41 87  8 38  1 51 22 47 90]\n",
      " [90 81 62 73  2 83 12  0  0 96  0 31 55 43 22 55 99 32 51 70 26 87 85 55]\n",
      " [80  8 91 48 17 76 86 60 66 38 10 28 38 79 40 43 78 34 10 90 60 21 76 70]\n",
      " [ 9  6 68 90 29  9 55 48 70 70 40 86 92 86 76 70 57 81 11 19 96 80 56 44]\n",
      " [ 4 21 82 13 54  1 29 72 93 68 17 40 82 40 86 81 89 81 40 96  3 61 36  1]\n",
      " [70 85 19 56 59  6 60 35 63  1 71 63 97 66 18 95 48 17 84 95 99 90 21 87]\n",
      " [11 22 43 69  0 52 59 93 76  6 57 51 74 47 16 26 72 95 52 90 84 67 99 61]\n",
      " [36 91 91 82 43 96 30 87 16 18  3 75 79 15 55 63 41  6 98 39 82 21 58 75]\n",
      " [91 43 88 13 67 93 29 49 11 80 62 64 40 47 70 85 18 54 74 34 37 87  4 59]\n",
      " [44  6  1 17 59 98 15 26 83 82 30 58 13 77 33 66 26 60 90 18 39 55 11 99]\n",
      " [79 88 63 15 84 42 50 20 27 60 91  1 22 19 97 59 96 58 49 26 85  3 43 18]\n",
      " [91 58 34 76 74  2 54 27 42 68  0 84 45 92 62 86 42 21 40 73 88 96 58  1]\n",
      " [10  6  2 93 92 18  6 41 36 43 82  0 63 60 52 99 75 28 68 58 64 50 18 27]\n",
      " [73 68 55  7 90 12 83 49 61 82 89 54 82 99 12 13  1 33 79 44 16 91  4  7]\n",
      " [87 94 28 96 32 54 97 53 49 80 49 64 99 40 65 51 10 57 34 37 46 68  7 61]]\n",
      "\n",
      "Randomly generated weight buffer:\n",
      "[[59 95 53 73 59 82 40  9 47 77 78 94 54 94  9 57 58 90 48 95 98 19 97 32]\n",
      " [83 82 36 87 45 23 16 87 86 41 21 21 66 73 43 99 36 43 58 30 58  8 98 51]\n",
      " [97 21 97 10 43 71 49 39 48 19 63 82 74 34 83 18 81 94 92 57 79 51 47 63]\n",
      " [97 64 86 25  8 28 76 86 72 27 86 44 24 11 88 16 93 94 85  8 56 11 22 63]\n",
      " [55  1 27 32 43 99 37 78 69 90 18 23 59 47 88 76 63 12 35 88  7 76 13 80]\n",
      " [ 6 67 69 40 92 93 79 28 92 72 17 46 70 37 73 10 57 29 31 93 66 27 34 45]\n",
      " [62 10 80 27  5 83 42 65 26 59 48 86 33 31 36 66 22  2 61 45 19 16 86 95]\n",
      " [36 92 23 17  7 85  9 45 12 64 72 65 82 37 47 67 12  9 50 21 72 19 51 36]\n",
      " [65  6 71 62 39 45 75 70 47 85 55 83 45 79 28 27 47 90 90 63 40 70 36 54]\n",
      " [40 63 31  2 25  8  0 19 56 29 33 56 12 72 23  8 16 75 84 44 78  2 47 79]\n",
      " [77  3 49 76 24 51 12 71 97 56 36 72 27 31 72 67 72  5 55 79 92 34  7  2]\n",
      " [83 29 73 22 61 26 70  5 81 46  5 28 65  6 82 82 43 12 57 37 94 93 85 89]\n",
      " [88 12 24  3 70 92 14  6  1 44 37 30  2 12 44 40 98  1  5 26 59 16 67 72]\n",
      " [85 69 14 48 36 52 95 41 95 85 41 62 99 35 56 26 97 65 94 83  5 38 86 47]\n",
      " [39 55 58 56 25 40 99 61 84 46 13 36 90 44 39 15 70 14 31 85 66  3 76 18]\n",
      " [72 73 22 87  7 93 18 80 14 93 69 58 64 80 62 11 69 98 52 87 88 45  4 33]\n",
      " [22 77 31  4 71 54 84  7 96  0 94 49 91 82 99 93 22 79 56 32 94 13 28 72]\n",
      " [81 20 85 79 16 90  3 34 23 80 34 11  6 35 53 91 38 25 40 24 53 92  4  8]\n",
      " [30 43  6 52 43 49 50 57 54 70  7 21 82 96 53 69 85 13 49 64 41  0 36 82]\n",
      " [32 30  9 63 89 74 12 81 22 83 82  1 29  4 46 54 15 35 74 34 23 49 10 72]\n",
      " [92 76 55  1 53 69  5 95 94 79 44 30 79 61 62 39 56  1 62  0 18 65 85 22]\n",
      " [ 6  1 92 82 51 35 92 10 45 63 60 28 94 23 42 23 79  2 47 36 22 66 67 80]\n",
      " [33 81 25 61 53 82  4 13  2 92  0 16 71 91 30 95 56 70 89 67  2 38 27 54]\n",
      " [ 0 74 78 52 89 26 62 45 64 62 44 84 33 68 22 46  2 87 64 59  7 89 45 57]]\n",
      "\n",
      "Randomly generated bias buffer:\n",
      "[[38 96 85 76 19 53 82  8 11 41 58 23 27 58 60 16  4 47 76 61 98 23 19 97]\n",
      " [31 81 89 73 59  0  8 10  8 99 46 35 78 79 54 49  6 97 98 95 49 29 34 54]\n",
      " [59 97 99 13 12 47 83 58 44 66 31 35 50 90 10 91 42 43 35 42  3 93 64  5]\n",
      " [10 11 94 81 82 65 86 34 14 99 86 29 19 41 64 94 98 11 21 21 27 83 73 17]\n",
      " [40 79 10 49 68 13 30 82  6 87 21 90 80 17 37 70 57 29 47 56 34 22  0 22]\n",
      " [26  0 68 51 51 23 47 63 28 80 73 46 62 54 80 54 48 51  7 51 63 64 88 53]\n",
      " [49 75 47 16 38 46 59 87 88 52 25  2 71 37  9 10 83 54 12 95  4 64 95 26]\n",
      " [74 78 14 69 16 91  5 96 73  8 14 76 91 41 93 47 73 40 76 97 81 66 98 60]\n",
      " [86 94 11 88 15 83 91 25 45 72 36 32 96 91  4 12 23  5 89 94 90 41 22 96]\n",
      " [59 27 38 24 50 26 92 31 96 39 43 45  5  7 95  6 73 83 16 20 73 27 80 74]\n",
      " [31 76  9 20 22  5  9 21 28 41 50 46 82 52 96 73 66 65 17 25 35 25 98 66]\n",
      " [ 8 66 53 18 86 38  5 32 85 79 10 58  3 10 41 23 86 44 31 37  7 96 60 79]\n",
      " [17 11 97 27  6 17 31  6  5 12 69 94 24  9 33 52 33 45 58 62 89  5 51 43]\n",
      " [12 93 64  3 69  7 38 97  2 64 29 77 78 76 33 48 52 50 72 94 65 41 40 86]\n",
      " [61  6 36 13 45  2 62  2  3 94 10 63 23 83 16 78 62 34 28 17 69 82 66 32]\n",
      " [60 75  5 97 72  8 49 16 29 50 92 50 86 21 99  6 78 61 51 75 16 44 12 24]\n",
      " [58 48 50 92 49 53 90 12 40 31 88 88 70 21 79 55 84 97 97 12 82  7 86 40]\n",
      " [26 73 38 55 39 67 75 93 43 29 27 10 88 42 43 36 48 25 52 90 43 84 32  4]\n",
      " [82 90 53 53 97 64 47 80 40 49 97 63 12 42  3 16  2 72 25 96 53 82 39  2]\n",
      " [51 92 98 50 57 88 35 64 90  1 71 24 16 26 52 91 75 34 99 13 28 82 19 49]\n",
      " [83 74 85 71 76 26 46 76 23 25 70 35  4 91  8  3 57  6 47 85  1 77 40 98]\n",
      " [29 74 28 70 75 86 54 92 10 30 12 98 80 89 37 16 49 85 43 79 60 99  2 85]\n",
      " [22 79 82 60 96 74 26 22 49 26 86 87 35  8 18 62 42  8 44 92 92 91 78 43]\n",
      " [83  8 46 24  2 31 29 61 28 26 12 72 61 10 73 47 93 69 21 12 42 77 54 83]]\n",
      "Packed input buffer:\n",
      "[40 92 29 15  7 45 14 82 20 53 30 63 39 74 90 46 10 97 47 25 34 82 16 84\n",
      " 43 54 76 31 67 84 34 52 35  6 72 22 49  1  8 39 52 90 74 78 33  4 91  3\n",
      " 46 54 12 43 95 90 99 52 68 20 25 33 42 83 56 22 30 82 73 75 75 42 50 85\n",
      " 32  2 31 78 55 47 51 80  4 24 57 29 10  8 30 47 81 37 91  7 65 56 57 11\n",
      " 73 38 44 66 37 99 20 88 62 29 31 64 91 57  4 48 31 30 90 33 84 57 68 78\n",
      " 54 24 66 41 74 56 90 74 62 84 11 58 87  1 46  9  5 46 80 14 96 27 63 77\n",
      " 78  6 83 69 76 70 29 54 13 32 52 70 68 79 56 49 64 56 88 67 16 95 69 49\n",
      "  9 76 68 24 74 19 39 55 93 78 45 69 73 83 25 88 76 85 16 50 14 89 42 46\n",
      " 64  8 26 18 22  3 28 82 90 81 62 73 80  8 91 48 94 50 37 51 43 75 40 39\n",
      "  2 83 12  0 17 76 86 60 49 35 15 39 20 73 14 22  0 96  0 31 66 38 10 28\n",
      " 42  7 75  8 30 57 12 41 55 43 22 55 38 79 40 43 49 87  1 62 87  8 38  1\n",
      " 99 32 51 70 78 34 10 90 41 17 11 99 51 22 47 90 26 87 85 55 60 21 76 70\n",
      "  9  6 68 90  4 21 82 13 70 85 19 56 11 22 43 69 29  9 55 48 54  1 29 72\n",
      " 59  6 60 35  0 52 59 93 70 70 40 86 93 68 17 40 63  1 71 63 76  6 57 51\n",
      " 92 86 76 70 82 40 86 81 97 66 18 95 74 47 16 26 57 81 11 19 89 81 40 96\n",
      " 48 17 84 95 72 95 52 90 96 80 56 44  3 61 36  1 99 90 21 87 84 67 99 61\n",
      " 36 91 91 82 91 43 88 13 44  6  1 17 79 88 63 15 43 96 30 87 67 93 29 49\n",
      " 59 98 15 26 84 42 50 20 16 18  3 75 11 80 62 64 83 82 30 58 27 60 91  1\n",
      " 79 15 55 63 40 47 70 85 13 77 33 66 22 19 97 59 41  6 98 39 18 54 74 34\n",
      " 26 60 90 18 96 58 49 26 82 21 58 75 37 87  4 59 39 55 11 99 85  3 43 18\n",
      " 91 58 34 76 10  6  2 93 73 68 55  7 87 94 28 96 74  2 54 27 92 18  6 41\n",
      " 90 12 83 49 32 54 97 53 42 68  0 84 36 43 82  0 61 82 89 54 49 80 49 64\n",
      " 45 92 62 86 63 60 52 99 82 99 12 13 99 40 65 51 42 21 40 73 75 28 68 58\n",
      "  1 33 79 44 10 57 34 37 88 96 58  1 64 50 18 27 16 91  4  7 46 68  7 61]\n",
      "Packed weight buffer:\n",
      "[59 95 53 73 83 82 36 87 97 21 97 10 97 64 86 25 59 82 40  9 45 23 16 87\n",
      " 43 71 49 39  8 28 76 86 47 77 78 94 86 41 21 21 48 19 63 82 72 27 86 44\n",
      " 54 94  9 57 66 73 43 99 74 34 83 18 24 11 88 16 58 90 48 95 36 43 58 30\n",
      " 81 94 92 57 93 94 85  8 98 19 97 32 58  8 98 51 79 51 47 63 56 11 22 63\n",
      " 55  1 27 32  6 67 69 40 62 10 80 27 36 92 23 17 43 99 37 78 92 93 79 28\n",
      "  5 83 42 65  7 85  9 45 69 90 18 23 92 72 17 46 26 59 48 86 12 64 72 65\n",
      " 59 47 88 76 70 37 73 10 33 31 36 66 82 37 47 67 63 12 35 88 57 29 31 93\n",
      " 22  2 61 45 12  9 50 21  7 76 13 80 66 27 34 45 19 16 86 95 72 19 51 36\n",
      " 65  6 71 62 40 63 31  2 77  3 49 76 83 29 73 22 39 45 75 70 25  8  0 19\n",
      " 24 51 12 71 61 26 70  5 47 85 55 83 56 29 33 56 97 56 36 72 81 46  5 28\n",
      " 45 79 28 27 12 72 23  8 27 31 72 67 65  6 82 82 47 90 90 63 16 75 84 44\n",
      " 72  5 55 79 43 12 57 37 40 70 36 54 78  2 47 79 92 34  7  2 94 93 85 89\n",
      " 88 12 24  3 85 69 14 48 39 55 58 56 72 73 22 87 70 92 14  6 36 52 95 41\n",
      " 25 40 99 61  7 93 18 80  1 44 37 30 95 85 41 62 84 46 13 36 14 93 69 58\n",
      "  2 12 44 40 99 35 56 26 90 44 39 15 64 80 62 11 98  1  5 26 97 65 94 83\n",
      " 70 14 31 85 69 98 52 87 59 16 67 72  5 38 86 47 66  3 76 18 88 45  4 33\n",
      " 22 77 31  4 81 20 85 79 30 43  6 52 32 30  9 63 71 54 84  7 16 90  3 34\n",
      " 43 49 50 57 89 74 12 81 96  0 94 49 23 80 34 11 54 70  7 21 22 83 82  1\n",
      " 91 82 99 93  6 35 53 91 82 96 53 69 29  4 46 54 22 79 56 32 38 25 40 24\n",
      " 85 13 49 64 15 35 74 34 94 13 28 72 53 92  4  8 41  0 36 82 23 49 10 72\n",
      " 92 76 55  1  6  1 92 82 33 81 25 61  0 74 78 52 53 69  5 95 51 35 92 10\n",
      " 53 82  4 13 89 26 62 45 94 79 44 30 45 63 60 28  2 92  0 16 64 62 44 84\n",
      " 79 61 62 39 94 23 42 23 71 91 30 95 33 68 22 46 56  1 62  0 79  2 47 36\n",
      " 56 70 89 67  2 87 64 59 18 65 85 22 22 66 67 80  2 38 27 54  7 89 45 57]\n",
      "Packed bias buffer:\n",
      "[38 96 85 76 31 81 89 73 59 97 99 13 10 11 94 81 19 53 82  8 59  0  8 10\n",
      " 12 47 83 58 82 65 86 34 11 41 58 23  8 99 46 35 44 66 31 35 14 99 86 29\n",
      " 27 58 60 16 78 79 54 49 50 90 10 91 19 41 64 94  4 47 76 61  6 97 98 95\n",
      " 42 43 35 42 98 11 21 21 98 23 19 97 49 29 34 54  3 93 64  5 27 83 73 17\n",
      " 40 79 10 49 26  0 68 51 49 75 47 16 74 78 14 69 68 13 30 82 51 23 47 63\n",
      " 38 46 59 87 16 91  5 96  6 87 21 90 28 80 73 46 88 52 25  2 73  8 14 76\n",
      " 80 17 37 70 62 54 80 54 71 37  9 10 91 41 93 47 57 29 47 56 48 51  7 51\n",
      " 83 54 12 95 73 40 76 97 34 22  0 22 63 64 88 53  4 64 95 26 81 66 98 60\n",
      " 86 94 11 88 59 27 38 24 31 76  9 20  8 66 53 18 15 83 91 25 50 26 92 31\n",
      " 22  5  9 21 86 38  5 32 45 72 36 32 96 39 43 45 28 41 50 46 85 79 10 58\n",
      " 96 91  4 12  5  7 95  6 82 52 96 73  3 10 41 23 23  5 89 94 73 83 16 20\n",
      " 66 65 17 25 86 44 31 37 90 41 22 96 73 27 80 74 35 25 98 66  7 96 60 79\n",
      " 17 11 97 27 12 93 64  3 61  6 36 13 60 75  5 97  6 17 31  6 69  7 38 97\n",
      " 45  2 62  2 72  8 49 16  5 12 69 94  2 64 29 77  3 94 10 63 29 50 92 50\n",
      " 24  9 33 52 78 76 33 48 23 83 16 78 86 21 99  6 33 45 58 62 52 50 72 94\n",
      " 62 34 28 17 78 61 51 75 89  5 51 43 65 41 40 86 69 82 66 32 16 44 12 24\n",
      " 58 48 50 92 26 73 38 55 82 90 53 53 51 92 98 50 49 53 90 12 39 67 75 93\n",
      " 97 64 47 80 57 88 35 64 40 31 88 88 43 29 27 10 40 49 97 63 90  1 71 24\n",
      " 70 21 79 55 88 42 43 36 12 42  3 16 16 26 52 91 84 97 97 12 48 25 52 90\n",
      "  2 72 25 96 75 34 99 13 82  7 86 40 43 84 32  4 53 82 39  2 28 82 19 49\n",
      " 83 74 85 71 29 74 28 70 22 79 82 60 83  8 46 24 76 26 46 76 75 86 54 92\n",
      " 96 74 26 22  2 31 29 61 23 25 70 35 10 30 12 98 49 26 86 87 28 26 12 72\n",
      "  4 91  8  3 80 89 37 16 35  8 18 62 61 10 73 47 57  6 47 85 49 85 43 79\n",
      " 42  8 44 92 93 69 21 12  1 77 40 98 60 99  2 85 92 91 78 43 42 77 54 83]\n",
      "pure software: 0.000477s\n",
      "Matrix multiplication result:\n",
      "[[55620 48237 47353 54916 48294 66022 40282 48817 54728 66229 41137 43927\n",
      "  54996 50690 53458 56987 54773 41712 57923 56889 52571 37684 45417 52263]\n",
      " [61792 59488 50115 48609 53088 71432 57974 55248 63184 68786 52370 48809\n",
      "  66763 50347 64507 54240 63835 49495 63369 59320 58676 39201 52723 61470]\n",
      " [68332 52983 55695 46095 52138 68976 43273 56965 63728 70289 48187 51075\n",
      "  60990 54211 62770 58869 61581 45910 71487 56565 59064 42859 57000 68329]\n",
      " [71198 57359 59815 57249 56601 80056 54595 63451 73809 76739 55148 55376\n",
      "  75524 57836 71322 62820 72683 49508 73190 67340 61226 46104 57892 62948]\n",
      " [76691 67325 72797 59553 62453 83132 61134 66434 73589 84303 64403 65365\n",
      "  76946 72584 70956 67375 73790 60662 81177 68825 72621 53333 71989 81376]\n",
      " [80253 63444 71895 68119 59252 87127 60436 75564 75379 91725 62830 63857\n",
      "  76027 66919 73221 71185 77116 55752 79211 68941 61634 59280 67112 74089]\n",
      " [61622 49806 57927 53219 40540 66083 44402 57031 60853 69278 48987 51778\n",
      "  60097 53633 57153 51837 61274 41856 61492 56992 54780 43433 51129 54362]\n",
      " [74146 63074 67828 64646 61514 84106 68399 62430 76927 86559 63674 69220\n",
      "  80635 66954 71842 71266 74081 57507 79144 76720 71399 53384 72107 79295]\n",
      " [49539 45171 52954 41785 48111 63476 43391 45443 54041 61902 44160 46795\n",
      "  50235 46886 50564 51072 44070 40952 52718 52715 48635 46755 45066 51593]\n",
      " [47113 53488 47242 32760 43941 54674 46431 41717 57454 53573 44292 48718\n",
      "  54241 50272 53640 42418 48752 50001 58247 49013 46640 34547 43247 55187]\n",
      " [60496 68298 58949 54101 61812 68616 54505 46926 66770 67422 57455 53481\n",
      "  69481 64980 62918 57881 64877 65582 73298 62235 66053 40281 59833 71015]\n",
      " [67181 65405 63951 50267 59344 80640 57136 56018 65458 76579 62759 65565\n",
      "  71735 61807 64518 58389 62275 64701 79183 66474 61292 48970 61651 68862]\n",
      " [84050 60136 73133 52643 53308 78539 61778 61011 73104 79119 61177 63085\n",
      "  74526 59581 74404 60356 77743 58844 81504 62823 68534 58125 67083 72723]\n",
      " [66389 48576 54872 51281 49161 74683 51086 53549 55454 70261 57291 51903\n",
      "  66494 55999 64561 57444 62661 53153 69375 60310 65232 47243 49960 67170]\n",
      " [81635 64265 65373 67045 65649 84214 59684 73490 76957 90105 66337 64371\n",
      "  78957 68685 73799 71978 78520 57113 80243 70011 67073 58781 71630 78848]\n",
      " [72638 61630 67410 56993 60312 83541 53897 60949 65617 82690 61961 57872\n",
      "  72406 60305 71145 70960 68103 53420 79671 58732 61987 56856 58646 70480]\n",
      " [72733 71051 63759 50959 61742 79540 56545 63660 72378 75601 54369 58127\n",
      "  78599 64801 73362 63966 71899 56095 73541 64282 69086 46613 66658 73638]\n",
      " [69068 61203 66894 60588 58025 79208 58367 57398 74360 79698 54654 63596\n",
      "  76212 64352 68939 57705 72751 54579 71363 76434 74287 51655 64394 69021]\n",
      " [53137 53424 55018 52094 52010 63492 55147 49969 66441 73920 43724 54489\n",
      "  63303 60306 56321 48455 57966 51096 64328 66007 54203 49793 50418 60373]\n",
      " [69470 60512 56371 53853 49937 74989 46490 62117 74144 70021 51260 56752\n",
      "  69686 68273 65990 64278 63345 51808 67272 67466 68167 40397 57008 57422]\n",
      " [78897 64953 62169 58514 55284 77407 59582 63032 72246 82819 60721 57594\n",
      "  79508 64415 69211 62126 75794 58881 79958 67306 64699 51459 71656 76177]\n",
      " [62118 50163 45879 47702 43862 67442 47505 59864 62833 67869 53131 47414\n",
      "  61252 53215 64870 49723 65811 46760 61823 57252 55284 40048 41466 57271]\n",
      " [72157 44817 56477 54740 49406 71480 50427 55031 65819 75102 50141 59294\n",
      "  65505 55570 60870 60991 69857 42615 69873 66371 60264 45530 65336 71329]\n",
      " [80753 63919 72853 60424 55963 78076 58415 64925 73807 79603 60782 66754\n",
      "  68123 61972 67467 63597 73390 56179 75960 67117 73569 48577 74456 75142]]\n"
     ]
    }
   ],
   "source": [
    "# 随机生成矩阵并存储到相应的数据缓冲区中\n",
    "np.random.seed(2)  # 设置随机种子以确保生成的随机数相同\n",
    "input_matrix = np.random.randint(0, 100, size=(row, col), dtype=Input_DataType)\n",
    "weight_matrix = np.random.randint(0, 100, size=(col, col1), dtype=Weight_DataType)\n",
    "bias_matrix = np.random.randint(0, 100, size=(row, col1), dtype=Output_DataType)\n",
    "print(\"Randomly generated input buffer:\")\n",
    "print(input_matrix)\n",
    "print(\"\\nRandomly generated weight buffer:\")\n",
    "print(weight_matrix)\n",
    "print(\"\\nRandomly generated bias buffer:\")\n",
    "print(bias_matrix)\n",
    "\n",
    "# 执行打包操作\n",
    "pack_matrix_to_buffer(input_matrix, MATRIX_WIDTH, input_buffer)\n",
    "pack_matrix_to_buffer(weight_matrix, MATRIX_WIDTH, weight_buffer)\n",
    "pack_matrix_to_buffer(bias_matrix, MATRIX_WIDTH, bias_buffer)\n",
    "print(\"Packed input buffer:\")\n",
    "print(input_buffer)\n",
    "print(\"Packed weight buffer:\")\n",
    "print(weight_buffer)\n",
    "print(\"Packed bias buffer:\")\n",
    "print(bias_buffer)\n",
    "\n",
    "# 将输入矩阵转换为np.int32类型，以避免溢出\n",
    "input_matrix_int32 = input_matrix.astype(np.int32)\n",
    "weight_matrix_int32 = weight_matrix.astype(np.int32)\n",
    "bias_matrix_int32 = bias_matrix.astype(np.int32)\n",
    "# 定义input_buffer和weight_buffer的矩阵乘法结果的结果矩阵\n",
    "pt0 = time.perf_counter()\n",
    "result_matrix = np.dot(input_matrix_int32, weight_matrix_int32) + bias_matrix_int32\n",
    "pt1 = time.perf_counter()\n",
    "time_sw = pt1 - pt0\n",
    "print(\"pure software: %fs\" % time_sw)\n",
    "# 打印矩阵乘法结果\n",
    "print(\"Matrix multiplication result:\")\n",
    "print(result_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分块矩阵乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 执行分块矩阵乘法\n",
    "blocked_gemm_test(saa_driver,\n",
    "              row, \n",
    "              col1, \n",
    "              col, \n",
    "              input_buffer, \n",
    "              weight_buffer,\n",
    "              bias_buffer, \n",
    "              output_buffer, \n",
    "              block_size, \n",
    "              1)\n",
    "# 解包并检查输出\n",
    "print(\"output_buffer result:\")\n",
    "print(output_buffer)\n",
    "output_matrix = np.zeros((row, col1), dtype=Output_DataType)\n",
    "unpack_buffer_to_matrix(output_matrix, MATRIX_WIDTH, output_buffer)\n",
    "print(\"un_pack result:\")\n",
    "print(output_matrix)\n",
    "output_buffer[:]=0\n",
    "# del output_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly generated input buffer:\n",
      "[[23  1 13 24  6 27 18 44 73 53  3  6 87 56 59 74]\n",
      " [72 99 15 31  0 25 69  2 21 99 62 17 43 24 19 74]\n",
      " [99 74 43 76  4 91 38 32 41 70 10 10 94 13 53 21]\n",
      " [27 63 44 13 38 23 96 88 20 95 49 44 37  7 93 54]\n",
      " [37 39  5 14 25  3 77 46 38 26 14 48 55 81 74 71]\n",
      " [90  5 25 90 22 10 31 45 66 99 29  2 73 66 23 63]\n",
      " [31 78 60 45 35  6  1 50 13 68 51 15 17 15 90  3]\n",
      " [65 69 94 94 66 27  1 18 68 97  2 13 29 25 21 72]\n",
      " [38 78 24 49 57 44 22 62 19 65  7 42 97 70 40 40]\n",
      " [43 44 97 33 30 11 89 65 79 53 66 71 48 80 76 81]\n",
      " [37 87 78 20 28 65 94 59 82 56 49 31 21 21 82 99]\n",
      " [ 1 55 78 86 54 70  5 28 86 90 31  9 36 54 86 33]\n",
      " [44  0 68 71 83 64 34 32 21 79 18 33  3 88 69 36]\n",
      " [63 55 68 96 37 62 57 56  8 27 23 56 71 69 39 37]\n",
      " [ 1 73 38 78 14 46 62 44 54 33  2 15 92  8  5  1]\n",
      " [44 29 57 85 31 86 80 48 17 51 17 16 74 12 62  7]]\n",
      "\n",
      "Randomly generated weight buffer:\n",
      "[[31 68 75 16 28 99 50 74 91 10 15 52 16 42 89 84]\n",
      " [39 80 75 92 32 78 37 41 16 43 20 22 19 94 18 41]\n",
      " [18 72 75 31 44 79 55  8 41 71 96 35 70 95 95 28]\n",
      " [98 13 80 64 19 37 69 21 52 30 69 53 66 48 14 13]\n",
      " [51 61 55 83 16 33 77 23  3 52 78 87 41 84 22 80]\n",
      " [49 66 76  2  8 38 28 20 55 92 36 88 66 92 90 42]\n",
      " [53 70 30  4 44 66 42 63 48 56 19 59 48 74 83 78]\n",
      " [54 32 48  5 80 65 36 95 91  2 88 97 10 43 21 49]\n",
      " [66 82  0 87 56 71 69 10 30 34 18 39 33 83 29 25]\n",
      " [83 32 92  7  5 48  6  9  1 36 33 92 64 15 37 97]\n",
      " [77 31 62 60  9 25 78 88 58 55 74 81 11 17  7 59]\n",
      " [84 12  5 10 43  4 49 17  1 80 38  5 38 76 40 41]\n",
      " [ 6 68 19 84 57 44 77  1 44 31  3  4 19 62 24 16]\n",
      " [59 52 36 17 98 82 39 19 18 50 36 70 65 23 50 35]\n",
      " [18 45 45 92 96 38 96  4 52 32 25  1 13 81 49 18]\n",
      " [25 33 63 63 12 64  2 28 35 13 87 94 64 29 99 33]]\n",
      "Packed input buffer:\n",
      "[23  1 13 24 72 99 15 31 99 74 43 76 27 63 44 13  6 27 18 44  0 25 69  2\n",
      "  4 91 38 32 38 23 96 88 73 53  3  6 21 99 62 17 41 70 10 10 20 95 49 44\n",
      " 87 56 59 74 43 24 19 74 94 13 53 21 37  7 93 54 37 39  5 14 90  5 25 90\n",
      " 31 78 60 45 65 69 94 94 25  3 77 46 22 10 31 45 35  6  1 50 66 27  1 18\n",
      " 38 26 14 48 66 99 29  2 13 68 51 15 68 97  2 13 55 81 74 71 73 66 23 63\n",
      " 17 15 90  3 29 25 21 72 38 78 24 49 43 44 97 33 37 87 78 20  1 55 78 86\n",
      " 57 44 22 62 30 11 89 65 28 65 94 59 54 70  5 28 19 65  7 42 79 53 66 71\n",
      " 82 56 49 31 86 90 31  9 97 70 40 40 48 80 76 81 21 21 82 99 36 54 86 33\n",
      " 44  0 68 71 63 55 68 96  1 73 38 78 44 29 57 85 83 64 34 32 37 62 57 56\n",
      " 14 46 62 44 31 86 80 48 21 79 18 33  8 27 23 56 54 33  2 15 17 51 17 16\n",
      "  3 88 69 36 71 69 39 37 92  8  5  1 74 12 62  7]\n",
      "Packed input buffer:\n",
      "[31 68 75 16 39 80 75 92 18 72 75 31 98 13 80 64 28 99 50 74 32 78 37 41\n",
      " 44 79 55  8 19 37 69 21 91 10 15 52 16 43 20 22 41 71 96 35 52 30 69 53\n",
      " 16 42 89 84 19 94 18 41 70 95 95 28 66 48 14 13 51 61 55 83 49 66 76  2\n",
      " 53 70 30  4 54 32 48  5 16 33 77 23  8 38 28 20 44 66 42 63 80 65 36 95\n",
      "  3 52 78 87 55 92 36 88 48 56 19 59 91  2 88 97 41 84 22 80 66 92 90 42\n",
      " 48 74 83 78 10 43 21 49 66 82  0 87 83 32 92  7 77 31 62 60 84 12  5 10\n",
      " 56 71 69 10  5 48  6  9  9 25 78 88 43  4 49 17 30 34 18 39  1 36 33 92\n",
      " 58 55 74 81  1 80 38  5 33 83 29 25 64 15 37 97 11 17  7 59 38 76 40 41\n",
      "  6 68 19 84 59 52 36 17 18 45 45 92 25 33 63 63 57 44 77  1 98 82 39 19\n",
      " 96 38 96  4 12 64  2 28 44 31  3  4 18 50 36 70 52 32 25  1 35 13 87 94\n",
      " 19 62 24 16 65 23 50 35 13 81 49 18 64 29 99 33]\n",
      "pure software: 0.000393s\n",
      "Matrix multiplication result:\n",
      "[[24987 29480 25807 28555 27965 32766 27694 13375 23178 19190 22626 30452\n",
      "  23071 30627 28060 22068]\n",
      " [34062 35328 40731 29885 20304 39995 27828 24688 25476 26291 25811 38416\n",
      "  26828 35212 33943 36255]\n",
      " [35518 42848 45164 34488 28638 45081 38295 22877 35412 31074 27533 38223\n",
      "  30317 48155 39227 34637]\n",
      " [38598 39159 42572 33418 33310 42301 37854 29117 32001 31627 36325 44065\n",
      "  28905 46872 37960 40761]\n",
      " [30109 33346 28580 29936 33739 37535 32295 21067 25283 24686 25860 33029\n",
      "  24698 37175 32950 29071]\n",
      " [39235 36115 40943 32164 29017 44383 35203 23209 31738 24161 32013 44321\n",
      "  31642 35284 34913 35455]\n",
      " [28696 28542 35681 30552 24798 31369 32104 18886 23136 22893 28179 28754\n",
      "  20099 35092 22651 26708]\n",
      " [38936 39875 47241 38118 24559 45479 35422 18750 26734 29830 38431 43551\n",
      "  35876 45817 37814 35370]\n",
      " [36179 38809 39842 35367 32706 41490 36688 21510 27618 30314 31611 39858\n",
      "  29854 44577 32527 33818]\n",
      " [47385 49312 46354 42449 44371 54911 48756 31569 37853 40762 45985 50622\n",
      "  39077 56845 49147 43080]\n",
      " [42438 49702 48309 42097 36417 52741 42628 30503 36957 38658 42275 50469\n",
      "  36738 58060 49462 41770]\n",
      " [42033 41578 45538 41775 32666 42954 42178 17257 28101 35663 38055 43721\n",
      "  36256 50396 35630 32844]\n",
      " [39898 35779 43212 28823 30472 39989 36905 19687 27147 33927 37932 45729\n",
      "  35908 43053 38845 36232]\n",
      " [41068 41256 44884 33904 34611 45725 41772 26352 35092 36004 38082 42994\n",
      "  35136 50259 41062 35399]\n",
      " [28692 31952 28437 28210 22730 31329 29470 15897 22696 24466 21858 26720\n",
      "  23120 38619 22976 22358]\n",
      " [34929 37646 40390 29465 28305 38145 37877 21862 32760 31982 30503 37735\n",
      "  30182 46339 36359 32252]]\n"
     ]
    }
   ],
   "source": [
    "# 随机生成矩阵并存储到相应的数据缓冲区中\n",
    "np.random.seed(3)  # 设置随机种子以确保生成的随机数相同\n",
    "input_matrix = np.random.randint(0, 100, size=(row, col), dtype=Input_DataType)\n",
    "weight_matrix = np.random.randint(0, 100, size=(col, col1), dtype=Weight_DataType)\n",
    "print(\"Randomly generated input buffer:\")\n",
    "print(input_matrix)\n",
    "print(\"\\nRandomly generated weight buffer:\")\n",
    "print(weight_matrix)\n",
    "\n",
    "# 执行打包操作\n",
    "pack_matrix_to_buffer(input_matrix, MATRIX_WIDTH, input_buffer)\n",
    "pack_matrix_to_buffer(weight_matrix, MATRIX_WIDTH, weight_buffer)\n",
    "print(\"Packed input buffer:\")\n",
    "print(input_buffer)\n",
    "print(\"Packed input buffer:\")\n",
    "print(weight_buffer)\n",
    "\n",
    "# 将输入矩阵转换为np.int32类型，以避免溢出\n",
    "input_matrix_int32 = input_matrix.astype(np.int32)\n",
    "weight_matrix_int32 = weight_matrix.astype(np.int32)\n",
    "# 定义input_buffer和weight_buffer的矩阵乘法结果的结果矩阵\n",
    "pt0 = time.perf_counter()\n",
    "result_matrix = np.dot(input_matrix_int32, weight_matrix_int32)\n",
    "pt1 = time.perf_counter()\n",
    "time_sw = pt1 - pt0\n",
    "print(\"pure software: %fs\" % time_sw)\n",
    "# 打印矩阵乘法结果\n",
    "print(\"Matrix multiplication result:\")\n",
    "print(result_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================================\n",
      "INFO - Blocked GEMM test: dim_I=16, dim_J=16, dim_K=16, block=8, bias_use=0\n",
      "compute_insn_count: 65\n",
      "insn_size: 130\n",
      "insn_idx: 90\n",
      "done: 2\n",
      "INFO - Saa run time: 0.000494s\n",
      "INFO - Synchronization time: 0.494095ms\n",
      "INFO - Throughput: 0.024870GOPs/s\n",
      "[[24987 29480 25807 28555 27965 32766 27694 13375 23178 19190 22626 30452\n",
      "  23071 30627 28060 22068]\n",
      " [34062 35328 40731 29885 20304 39995 27828 24688 25476 26291 25811 38416\n",
      "  26828 35212 33943 36255]\n",
      " [35518 42848 45164 34488 28638 45081 38295 22877 35412 31074 27533 38223\n",
      "  30317 48155 39227 34637]\n",
      " [38598 39159 42572 33418 33310 42301 37854 29117 32001 31627 36325 44065\n",
      "  28905 46872 37960 40761]\n",
      " [30109 33346 28580 29936 33739 37535 32295 21067 25283 24686 25860 33029\n",
      "  24698 37175 32950 29071]\n",
      " [39235 36115 40943 32164 29017 44383 35203 23209 31738 24161 32013 44321\n",
      "  31642 35284 34913 35455]\n",
      " [28696 28542 35681 30552 24798 31369 32104 18886 23136 22893 28179 28754\n",
      "  20099 35092 22651 26708]\n",
      " [38936 39875 47241 38118 24559 45479 35422 18750 26734 29830 38431 43551\n",
      "  35876 45817 37814 35370]\n",
      " [36179 38809 39842 35367 32706 41490 36688 21510 27618 30314 31611 39858\n",
      "  29854 44577 32527 33818]\n",
      " [47385 49312 46354 42449 44371 54911 48756 31569 37853 40762 45985 50622\n",
      "  39077 56845 49147 43080]\n",
      " [42438 49702 48309 42097 36417 52741 42628 30503 36957 38658 42275 50469\n",
      "  36738 58060 49462 41770]\n",
      " [42033 41578 45538 41775 32666 42954 42178 17257 28101 35663 38055 43721\n",
      "  36256 50396 35630 32844]\n",
      " [39898 35779 43212 28823 30472 39989 36905 19687 27147 33927 37932 45729\n",
      "  35908 43053 38845 36232]\n",
      " [41068 41256 44884 33904 34611 45725 41772 26352 35092 36004 38082 42994\n",
      "  35136 50259 41062 35399]\n",
      " [28692 31952 28437 28210 22730 31329 29470 15897 22696 24466 21858 26720\n",
      "  23120 38619 22976 22358]\n",
      " [34929 37646 40390 29465 28305 38145 37877 21862 32760 31982 30503 37735\n",
      "  30182 46339 36359 32252]]\n"
     ]
    }
   ],
   "source": [
    "# 执行分块矩阵乘法\n",
    "blocked_gemm_test(saa_driver,\n",
    "              row, \n",
    "              col1, \n",
    "              col, \n",
    "              input_buffer, \n",
    "              weight_buffer,\n",
    "              bias_buffer, \n",
    "              output_buffer, \n",
    "              block_size, \n",
    "              0)\n",
    "# 检查输出\n",
    "print(output_buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 回收缓冲区"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看完成后清空缓冲区\n",
    "del output_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instruct_buffer = allocate(shape = (1), cacheable = 0, dtype = Instruct_DataType)\n",
    "# instructions = [] #临时存储指令\n",
    "# # insn_test = getWeightPreloadComputeInsn(\n",
    "# #     1,\n",
    "# #     1,\n",
    "# #     1,\n",
    "# #     1,\n",
    "# #     1,\n",
    "# #     1)\n",
    "\n",
    "# # insn_test = getWeightPreloadInsn(1, 1)\n",
    "\n",
    "# # insn_test = get2DLoadStoreInsn(\n",
    "# #                           1, \n",
    "# #                           1, \n",
    "# #                           1, \n",
    "# #                           1, \n",
    "# #                           1, \n",
    "# #                           1, \n",
    "# #                           1)\n",
    "\n",
    "# insn_test = getComputeInsn(1, \n",
    "#                         1, \n",
    "#                         1, \n",
    "#                         1)\n",
    "    \n",
    "# instructions.append(insn_test)\n",
    "# # 将生成的指令批量存入缓冲区，然后启动saa让其读取指令\n",
    "# for i, instruction in enumerate(instructions):\n",
    "#     instruct_buffer[i] = np.frombuffer(instruction, dtype=Instruct_DataType)\n",
    "#     print(instruct_buffer[i])\n",
    "#     print_binary(instruct_buffer[i]) # 输出指令的二进制表示\n",
    "\n",
    "\n",
    "# from pynq import allocate\n",
    "# import time\n",
    "# import numpy as np\n",
    "# wait_cycles = 100000 # 定义一次最多等待周期为1000万周期\n",
    "# def blocked_gemm_test(saa_driver,\n",
    "#               dim_I, \n",
    "#               dim_J, \n",
    "#               dim_K, \n",
    "#               input, \n",
    "#               weight,\n",
    "#               bias, \n",
    "#               output, \n",
    "#               block, \n",
    "#               bias_use):\n",
    "    \n",
    "#     print(\"=====================================================================================\")\n",
    "#     print(f\"INFO - Blocked GEMM test: dim_I={dim_I}, dim_J={dim_J}, dim_K={dim_K}, block={block}, bias_use={bias_use}\")\n",
    "    \n",
    "#     # 计算分块\n",
    "#     dim_I_block = dim_I // MATRIX_WIDTH\n",
    "#     dim_J_block = dim_J // MATRIX_WIDTH\n",
    "#     dim_K_block = dim_K // MATRIX_WIDTH\n",
    "\n",
    "#     # 计算指令数量\n",
    "#     insn_load_size = (dim_I_block * dim_K_block) + (dim_J_block * dim_K_block)\n",
    "#     insn_compute_size = 2 * dim_I_block * dim_K_block * dim_J_block  # 不使用权重复用\n",
    "# #     insn_compute_size = (dim_I_block + 1) * dim_K_block * dim_J_block  # 使用权重复用\n",
    "# #     insn_compute_size = dim_I_block * dim_K_block * dim_J_block + 1  # 使用权重复用和双缓冲\n",
    "#     insn_store_size = dim_I_block * dim_J_block\n",
    "#     insn_size = insn_load_size + insn_store_size + insn_compute_size + 1\n",
    "\n",
    "#     # 初始化指令队列\n",
    "#     insn_buf = allocate(shape = (insn_size), cacheable = 0, dtype = Instruct_DataType)\n",
    "#     insn_idx = 0\n",
    "    \n",
    "#     # 生成加载Input指令\n",
    "#     for i in range(dim_I_block):\n",
    "#         for k in range(dim_K_block):\n",
    "#             buffer_start = 0\n",
    "#             dram_start = 0\n",
    "#             A_block = i*dim_K_block+k\n",
    "#             buffer_offset = buffer_start + A_block * MATRIX_WIDTH\n",
    "#             dram_offset = dram_start + i * dim_K_block * MATRIX_WIDTH * MATRIX_WIDTH + k * MATRIX_WIDTH\n",
    "#             insn_buf[insn_idx] = get2DLoadStoreInsn(OPCODE_LOAD, \n",
    "#                                       INPUT_BUFFER_ID, \n",
    "#                                       buffer_offset, \n",
    "#                                       dram_offset, \n",
    "#                                       MATRIX_WIDTH, \n",
    "#                                       MATRIX_WIDTH, \n",
    "#                                       dim_K)\n",
    "#             insn_idx += 1\n",
    "\n",
    "#     # 生成加载weight指令\n",
    "#     for k in range(dim_K_block):\n",
    "#         for j in range(dim_J_block):\n",
    "#             buffer_start = 0\n",
    "#             dram_start = 0\n",
    "#             A_block = k * dim_J_block + j\n",
    "#             buffer_offset = buffer_start + A_block * MATRIX_WIDTH\n",
    "#             dram_offset = dram_start + k * dim_J_block * MATRIX_WIDTH * MATRIX_WIDTH + j * MATRIX_WIDTH \n",
    "#             insn_buf[insn_idx] = get2DLoadStoreInsn(OPCODE_LOAD, \n",
    "#                                       WEIGHT_BUFFER_ID, \n",
    "#                                       buffer_offset, \n",
    "#                                       dram_offset, \n",
    "#                                       MATRIX_WIDTH, \n",
    "#                                       MATRIX_WIDTH, \n",
    "#                                       dim_J)\n",
    "#             insn_idx += 1\n",
    "    \n",
    "#     # 生成计算指令\n",
    "#     # 用于切换权重寄存器，最先使用 weight1\n",
    "#     pingpang = 0\n",
    "#     wb_start_addr = 0\n",
    "#     input_start_addr = 0\n",
    "#     output_start_addr = 0\n",
    "#     weight_offset = 0\n",
    "#     output_offset = 0\n",
    "#     input_offset = 0\n",
    "#     accumulate = 0\n",
    "    \n",
    "#     # 初始化指令计数\n",
    "#     compute_count = insn_idx\n",
    "\n",
    "#     # 迭代公共维度块和输出列块\n",
    "#     for k in range(dim_K_block):\n",
    "#         for j in range(dim_J_block):\n",
    "#             # 计算权重偏移\n",
    "#             weight_offset = wb_start_addr + (k * dim_J_block + j) * MATRIX_WIDTH\n",
    "#             accumulate = 0 if k == 0 else 1\n",
    "\n",
    "#             # 第一次加载权重，使用初始寄存器，无法双缓冲\n",
    "#             if k == 0 and j == 0:\n",
    "#                 insn_buf[insn_idx] = getWeightPreloadInsn(weight_offset, pingpang)\n",
    "#                 insn_idx += 1\n",
    "#             else:\n",
    "#                 # 剩下的权重加载可以进行双缓冲\n",
    "# #                 insn_buf[insn_idx] = getWeightPreloadComputeInsn(\n",
    "# #                     input_offset,\n",
    "# #                     weight_offset,\n",
    "# #                     output_offset,\n",
    "# #                     pingpang,\n",
    "# #                     pingpang,\n",
    "# #                     accumulate)\n",
    "# #                 insn_idx += 1\n",
    "    \n",
    "# #                 insn_buf[insn_idx] = getComputeInsn(input_offset, \n",
    "# #                                         output_offset, \n",
    "# #                                         pingpang, \n",
    "# #                                         accumulate)\n",
    "# #                 insn_idx += 1\n",
    "#                 insn_buf[insn_idx] = getComputeInsn(input_offset, \n",
    "#                                         output_offset, \n",
    "#                                         pingpang, \n",
    "#                                         accumulate)\n",
    "#                 insn_idx += 1\n",
    "#                 insn_buf[insn_idx] = getWeightPreloadInsn(weight_offset, not pingpang)\n",
    "#                 insn_idx += 1\n",
    "                \n",
    "#                 pingpang = not pingpang  # 切换加载寄存器和计算寄存器\n",
    "\n",
    "\n",
    "#             # 迭代输出行块\n",
    "#             for i in range(dim_I_block):\n",
    "#                 output_offset = output_start_addr + (i * dim_J_block + j) * MATRIX_WIDTH\n",
    "#                 input_offset = input_start_addr + (i * dim_K_block + k) * MATRIX_WIDTH\n",
    "\n",
    "#                 # 如果不是最后一个计算，使用 getComputeInsn 计算\n",
    "#                 if i != dim_I_block - 1:\n",
    "#                     insn_buf[insn_idx] = getComputeInsn(input_offset, \n",
    "#                                             output_offset, \n",
    "#                                             pingpang, \n",
    "#                                             accumulate)\n",
    "#                     insn_idx += 1\n",
    "#                 # 如果是最后一个权重块，使用当前寄存器进行计算\n",
    "#                 if i == dim_I_block - 1 and j == dim_J_block - 1 and k == dim_K_block - 1:\n",
    "#                     insn_buf[insn_idx] = getComputeInsn(input_offset, \n",
    "#                                             output_offset, \n",
    "#                                             pingpang, \n",
    "#                                             accumulate)\n",
    "#                     insn_idx += 1\n",
    "# #             if k != 0 and j != 0:\n",
    "# #             insn_buf[insn_idx] = getComputeInsn(input_offset, \n",
    "# #                                     output_offset, \n",
    "# #                                     pingpang, \n",
    "# #                                     accumulate)\n",
    "#             insn_idx += 1\n",
    "    \n",
    "    \n",
    "#     # 更新计算指令的数量\n",
    "#     compute_count = insn_idx - compute_count\n",
    "#     print(f\"compute_count: {compute_count}\")    \n",
    "\n",
    "    \n",
    "#     # 生成存储指令\n",
    "#     for i in range(dim_I_block):\n",
    "#         for j in range(dim_J_block):\n",
    "#             buffer_start = 0\n",
    "#             dram_start = 0\n",
    "#             A_block = i * dim_J_block + j\n",
    "#             buffer_offset = buffer_start + A_block * MATRIX_WIDTH\n",
    "#             dram_offset = dram_start + i * dim_J_block * MATRIX_WIDTH * MATRIX_WIDTH + j * MATRIX_WIDTH\n",
    "#             insn_buf[insn_idx] = get2DLoadStoreInsn(OPCODE_STORE, \n",
    "#                                        OUTPUT_BUFFER_ID, \n",
    "#                                        buffer_offset, \n",
    "#                                        dram_offset, \n",
    "#                                        MATRIX_WIDTH, \n",
    "#                                        MATRIX_WIDTH, \n",
    "#                                        dim_J)\n",
    "#             insn_idx += 1\n",
    "            \n",
    "#     # 生成结束指令\n",
    "#     insn_buf[insn_idx] = getFinishInsn()\n",
    "#     insn_idx += 1\n",
    "\n",
    "#     print(\"insn_size\",insn_size)\n",
    "#     print(\"insn_idx\",insn_idx)\n",
    "#     print(\"insn\",insn_idx)\n",
    "#     for i in range(insn_idx):\n",
    "#         if i>=insn_load_size and i<insn_load_size+compute_count:\n",
    "#             print_binary(insn_buf[i])\n",
    "            \n",
    "#     # 运行SAA硬件\n",
    "#     pt0 = time.perf_counter()\n",
    "#     saa_driver.run_saa(insn_idx,\n",
    "#            insn_buf.physical_address,\n",
    "#            input.physical_address,\n",
    "#            weight.physical_address,\n",
    "#            output.physical_address,\n",
    "#            wait_cycles)\n",
    "#     pt1 = time.perf_counter()\n",
    "#     time_sw = pt1 - pt0\n",
    "#     print(\"saa run time: %fs\" % time_sw)     \n",
    "    \n",
    "#     # 计算吞吐量\n",
    "    \n",
    "    \n",
    "#     return 0 \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
