{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAA_top测试\n",
    "## 1. 加载Overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pynq import allocate\n",
    "import random\n",
    "import time\n",
    "import saa_top_driver\n",
    "from saa_insn_driver import * \n",
    "from saa_utils import * \n",
    "# 创建 SaaDriver 实例\n",
    "saa_driver = saa_top_driver.SaaDriver(\"saa_top.bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据类型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insn_buf[insn_idx] = get2DLoadStoreInsn(OPCODE_LOAD, \n",
    "                          INPUT_BUFFER_ID, \n",
    "                          0, \n",
    "                          0, \n",
    "                          1, \n",
    "                          block*block,\n",
    "                          dim_K)# 直接加载一整个块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.连续缓存申请"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义指令缓冲区大小\n",
    "insn_count = 4000 # 最多能容纳2000条指令\n",
    "\n",
    "# 定义buffer大小,这是执行一个批量的大小\n",
    "row =  2*MATRIX_WIDTH\n",
    "col =  2*MATRIX_WIDTH\n",
    "col1 = 2*MATRIX_WIDTH\n",
    "\n",
    "# 定义PS端缓冲区,不使用cache，数据类型注意\n",
    "# instruct_buffer = allocate(shape = (insn_count), cacheable = 0, dtype = Instruct_DataType)\n",
    "input_buffer = allocate(shape = (row, col), cacheable = 0, dtype = Input_DataType)\n",
    "weight_buffer = allocate(shape = (col, col1), cacheable = 0, dtype = Weight_DataType)\n",
    "output_buffer  = allocate(shape = (row,col1), cacheable = 0, dtype = Output_DataType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.测试数据生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机生成矩阵并存储到相应的数据缓冲区中\n",
    "np.random.seed(2)  # 设置随机种子以确保生成的随机数相同\n",
    "input_buffer[:] = np.random.randint(0, 100, size=(row, col), dtype=np.int8)\n",
    "weight_buffer[:] = np.random.randint(0, 100, size=(col, col1), dtype=np.int8)\n",
    "\n",
    "# 将输入矩阵转换为np.int32类型，以避免溢出\n",
    "input_buffer_int32 = input_buffer.astype(np.int32)\n",
    "weight_buffer_int32 = weight_buffer.astype(np.int32)\n",
    "\n",
    "# 打印生成的随机矩阵\n",
    "print(\"Randomly generated input buffer:\")\n",
    "print(input_buffer)\n",
    "\n",
    "print(\"\\nRandomly generated weight buffer:\")\n",
    "print(weight_buffer)\n",
    "\n",
    "# 定义input_buffer和weight_buffer的矩阵乘法结果的结果矩阵\n",
    "pt0 = time.perf_counter()\n",
    "result_matrix = np.dot(input_buffer_int32, weight_buffer_int32)\n",
    "pt1 = time.perf_counter()\n",
    "time_sw = pt1 - pt0\n",
    "print(\"pure software: %fs\" % time_sw)\n",
    "\n",
    "\n",
    "# 打印矩阵乘法结果\n",
    "print(\"Matrix multiplication result:\")\n",
    "print(result_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分块矩阵乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 执行分块矩阵乘法\n",
    "blocked_gemm_test(saa_driver,\n",
    "              row, \n",
    "              col1, \n",
    "              col, \n",
    "              input_buffer, \n",
    "              weight_buffer,\n",
    "              0, \n",
    "              output_buffer, \n",
    "              0, \n",
    "              0)\n",
    "# 检查输出\n",
    "print(output_buffer)\n",
    "output_buffer[:]=0\n",
    "# del output_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机生成矩阵并存储到相应的数据缓冲区中\n",
    "np.random.seed(3)  # 设置随机种子以确保生成的随机数相同\n",
    "input_buffer[:] = np.random.randint(0, 100, size=(row, col), dtype=np.int8)\n",
    "weight_buffer[:] = np.random.randint(0, 100, size=(col, col1), dtype=np.int8)\n",
    "\n",
    "# 将输入矩阵转换为np.int32类型，以避免溢出\n",
    "input_buffer_int32 = input_buffer.astype(np.int32)\n",
    "weight_buffer_int32 = weight_buffer.astype(np.int32)\n",
    "\n",
    "# 打印生成的随机矩阵\n",
    "print(\"Randomly generated input buffer:\")\n",
    "print(input_buffer)\n",
    "\n",
    "print(\"\\nRandomly generated weight buffer:\")\n",
    "print(weight_buffer)\n",
    "\n",
    "# 定义input_buffer和weight_buffer的矩阵乘法结果的结果矩阵\n",
    "pt0 = time.perf_counter()\n",
    "result_matrix = np.dot(input_buffer_int32, weight_buffer_int32)\n",
    "pt1 = time.perf_counter()\n",
    "time_sw = pt1 - pt0\n",
    "print(\"pure software: %fs\" % time_sw)\n",
    "\n",
    "\n",
    "# 打印矩阵乘法结果\n",
    "print(\"Matrix multiplication result:\")\n",
    "print(result_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 执行分块矩阵乘法\n",
    "blocked_gemm_test(saa_driver,\n",
    "              row, \n",
    "              col1, \n",
    "              col, \n",
    "              input_buffer, \n",
    "              weight_buffer,\n",
    "              0, \n",
    "              output_buffer, \n",
    "              0, \n",
    "              0)\n",
    "# 检查输出\n",
    "print(output_buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 回收缓冲区"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看完成后清空缓冲区\n",
    "del output_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instruct_buffer = allocate(shape = (1), cacheable = 0, dtype = Instruct_DataType)\n",
    "# instructions = [] #临时存储指令\n",
    "# # insn_test = getWeightPreloadComputeInsn(\n",
    "# #     1,\n",
    "# #     1,\n",
    "# #     1,\n",
    "# #     1,\n",
    "# #     1,\n",
    "# #     1)\n",
    "\n",
    "# # insn_test = getWeightPreloadInsn(1, 1)\n",
    "\n",
    "# # insn_test = get2DLoadStoreInsn(\n",
    "# #                           1, \n",
    "# #                           1, \n",
    "# #                           1, \n",
    "# #                           1, \n",
    "# #                           1, \n",
    "# #                           1, \n",
    "# #                           1)\n",
    "\n",
    "# insn_test = getComputeInsn(1, \n",
    "#                         1, \n",
    "#                         1, \n",
    "#                         1)\n",
    "    \n",
    "# instructions.append(insn_test)\n",
    "# # 将生成的指令批量存入缓冲区，然后启动saa让其读取指令\n",
    "# for i, instruction in enumerate(instructions):\n",
    "#     instruct_buffer[i] = np.frombuffer(instruction, dtype=Instruct_DataType)\n",
    "#     print(instruct_buffer[i])\n",
    "#     print_binary(instruct_buffer[i]) # 输出指令的二进制表示\n",
    "\n",
    "\n",
    "# from pynq import allocate\n",
    "# import time\n",
    "# import numpy as np\n",
    "# wait_cycles = 100000 # 定义一次最多等待周期为1000万周期\n",
    "# def blocked_gemm_test(saa_driver,\n",
    "#               dim_I, \n",
    "#               dim_J, \n",
    "#               dim_K, \n",
    "#               input, \n",
    "#               weight,\n",
    "#               bias, \n",
    "#               output, \n",
    "#               block, \n",
    "#               bias_use):\n",
    "    \n",
    "#     print(\"=====================================================================================\")\n",
    "#     print(f\"INFO - Blocked GEMM test: dim_I={dim_I}, dim_J={dim_J}, dim_K={dim_K}, block={block}, bias_use={bias_use}\")\n",
    "    \n",
    "#     # 计算分块\n",
    "#     dim_I_block = dim_I // MATRIX_WIDTH\n",
    "#     dim_J_block = dim_J // MATRIX_WIDTH\n",
    "#     dim_K_block = dim_K // MATRIX_WIDTH\n",
    "\n",
    "#     # 计算指令数量\n",
    "#     insn_load_size = (dim_I_block * dim_K_block) + (dim_J_block * dim_K_block)\n",
    "#     insn_compute_size = 2 * dim_I_block * dim_K_block * dim_J_block  # 不使用权重复用\n",
    "# #     insn_compute_size = (dim_I_block + 1) * dim_K_block * dim_J_block  # 使用权重复用\n",
    "# #     insn_compute_size = dim_I_block * dim_K_block * dim_J_block + 1  # 使用权重复用和双缓冲\n",
    "#     insn_store_size = dim_I_block * dim_J_block\n",
    "#     insn_size = insn_load_size + insn_store_size + insn_compute_size + 1\n",
    "\n",
    "#     # 初始化指令队列\n",
    "#     insn_buf = allocate(shape = (insn_size), cacheable = 0, dtype = Instruct_DataType)\n",
    "#     insn_idx = 0\n",
    "    \n",
    "#     # 生成加载Input指令\n",
    "#     for i in range(dim_I_block):\n",
    "#         for k in range(dim_K_block):\n",
    "#             buffer_start = 0\n",
    "#             dram_start = 0\n",
    "#             A_block = i*dim_K_block+k\n",
    "#             buffer_offset = buffer_start + A_block * MATRIX_WIDTH\n",
    "#             dram_offset = dram_start + i * dim_K_block * MATRIX_WIDTH * MATRIX_WIDTH + k * MATRIX_WIDTH\n",
    "#             insn_buf[insn_idx] = get2DLoadStoreInsn(OPCODE_LOAD, \n",
    "#                                       INPUT_BUFFER_ID, \n",
    "#                                       buffer_offset, \n",
    "#                                       dram_offset, \n",
    "#                                       MATRIX_WIDTH, \n",
    "#                                       MATRIX_WIDTH, \n",
    "#                                       dim_K)\n",
    "#             insn_idx += 1\n",
    "\n",
    "#     # 生成加载weight指令\n",
    "#     for k in range(dim_K_block):\n",
    "#         for j in range(dim_J_block):\n",
    "#             buffer_start = 0\n",
    "#             dram_start = 0\n",
    "#             A_block = k * dim_J_block + j\n",
    "#             buffer_offset = buffer_start + A_block * MATRIX_WIDTH\n",
    "#             dram_offset = dram_start + k * dim_J_block * MATRIX_WIDTH * MATRIX_WIDTH + j * MATRIX_WIDTH \n",
    "#             insn_buf[insn_idx] = get2DLoadStoreInsn(OPCODE_LOAD, \n",
    "#                                       WEIGHT_BUFFER_ID, \n",
    "#                                       buffer_offset, \n",
    "#                                       dram_offset, \n",
    "#                                       MATRIX_WIDTH, \n",
    "#                                       MATRIX_WIDTH, \n",
    "#                                       dim_J)\n",
    "#             insn_idx += 1\n",
    "    \n",
    "#     # 生成计算指令\n",
    "#     # 用于切换权重寄存器，最先使用 weight1\n",
    "#     pingpang = 0\n",
    "#     wb_start_addr = 0\n",
    "#     input_start_addr = 0\n",
    "#     output_start_addr = 0\n",
    "#     weight_offset = 0\n",
    "#     output_offset = 0\n",
    "#     input_offset = 0\n",
    "#     accumulate = 0\n",
    "    \n",
    "#     # 初始化指令计数\n",
    "#     compute_count = insn_idx\n",
    "\n",
    "#     # 迭代公共维度块和输出列块\n",
    "#     for k in range(dim_K_block):\n",
    "#         for j in range(dim_J_block):\n",
    "#             # 计算权重偏移\n",
    "#             weight_offset = wb_start_addr + (k * dim_J_block + j) * MATRIX_WIDTH\n",
    "#             accumulate = 0 if k == 0 else 1\n",
    "\n",
    "#             # 第一次加载权重，使用初始寄存器，无法双缓冲\n",
    "#             if k == 0 and j == 0:\n",
    "#                 insn_buf[insn_idx] = getWeightPreloadInsn(weight_offset, pingpang)\n",
    "#                 insn_idx += 1\n",
    "#             else:\n",
    "#                 # 剩下的权重加载可以进行双缓冲\n",
    "# #                 insn_buf[insn_idx] = getWeightPreloadComputeInsn(\n",
    "# #                     input_offset,\n",
    "# #                     weight_offset,\n",
    "# #                     output_offset,\n",
    "# #                     pingpang,\n",
    "# #                     pingpang,\n",
    "# #                     accumulate)\n",
    "# #                 insn_idx += 1\n",
    "    \n",
    "# #                 insn_buf[insn_idx] = getComputeInsn(input_offset, \n",
    "# #                                         output_offset, \n",
    "# #                                         pingpang, \n",
    "# #                                         accumulate)\n",
    "# #                 insn_idx += 1\n",
    "#                 insn_buf[insn_idx] = getComputeInsn(input_offset, \n",
    "#                                         output_offset, \n",
    "#                                         pingpang, \n",
    "#                                         accumulate)\n",
    "#                 insn_idx += 1\n",
    "#                 insn_buf[insn_idx] = getWeightPreloadInsn(weight_offset, not pingpang)\n",
    "#                 insn_idx += 1\n",
    "                \n",
    "#                 pingpang = not pingpang  # 切换加载寄存器和计算寄存器\n",
    "\n",
    "\n",
    "#             # 迭代输出行块\n",
    "#             for i in range(dim_I_block):\n",
    "#                 output_offset = output_start_addr + (i * dim_J_block + j) * MATRIX_WIDTH\n",
    "#                 input_offset = input_start_addr + (i * dim_K_block + k) * MATRIX_WIDTH\n",
    "\n",
    "#                 # 如果不是最后一个计算，使用 getComputeInsn 计算\n",
    "#                 if i != dim_I_block - 1:\n",
    "#                     insn_buf[insn_idx] = getComputeInsn(input_offset, \n",
    "#                                             output_offset, \n",
    "#                                             pingpang, \n",
    "#                                             accumulate)\n",
    "#                     insn_idx += 1\n",
    "#                 # 如果是最后一个权重块，使用当前寄存器进行计算\n",
    "#                 if i == dim_I_block - 1 and j == dim_J_block - 1 and k == dim_K_block - 1:\n",
    "#                     insn_buf[insn_idx] = getComputeInsn(input_offset, \n",
    "#                                             output_offset, \n",
    "#                                             pingpang, \n",
    "#                                             accumulate)\n",
    "#                     insn_idx += 1\n",
    "# #             if k != 0 and j != 0:\n",
    "# #             insn_buf[insn_idx] = getComputeInsn(input_offset, \n",
    "# #                                     output_offset, \n",
    "# #                                     pingpang, \n",
    "# #                                     accumulate)\n",
    "#             insn_idx += 1\n",
    "    \n",
    "    \n",
    "#     # 更新计算指令的数量\n",
    "#     compute_count = insn_idx - compute_count\n",
    "#     print(f\"compute_count: {compute_count}\")    \n",
    "\n",
    "    \n",
    "#     # 生成存储指令\n",
    "#     for i in range(dim_I_block):\n",
    "#         for j in range(dim_J_block):\n",
    "#             buffer_start = 0\n",
    "#             dram_start = 0\n",
    "#             A_block = i * dim_J_block + j\n",
    "#             buffer_offset = buffer_start + A_block * MATRIX_WIDTH\n",
    "#             dram_offset = dram_start + i * dim_J_block * MATRIX_WIDTH * MATRIX_WIDTH + j * MATRIX_WIDTH\n",
    "#             insn_buf[insn_idx] = get2DLoadStoreInsn(OPCODE_STORE, \n",
    "#                                        OUTPUT_BUFFER_ID, \n",
    "#                                        buffer_offset, \n",
    "#                                        dram_offset, \n",
    "#                                        MATRIX_WIDTH, \n",
    "#                                        MATRIX_WIDTH, \n",
    "#                                        dim_J)\n",
    "#             insn_idx += 1\n",
    "            \n",
    "#     # 生成结束指令\n",
    "#     insn_buf[insn_idx] = getFinishInsn()\n",
    "#     insn_idx += 1\n",
    "\n",
    "#     print(\"insn_size\",insn_size)\n",
    "#     print(\"insn_idx\",insn_idx)\n",
    "#     print(\"insn\",insn_idx)\n",
    "#     for i in range(insn_idx):\n",
    "#         if i>=insn_load_size and i<insn_load_size+compute_count:\n",
    "#             print_binary(insn_buf[i])\n",
    "            \n",
    "#     # 运行SAA硬件\n",
    "#     pt0 = time.perf_counter()\n",
    "#     saa_driver.run_saa(insn_idx,\n",
    "#            insn_buf.physical_address,\n",
    "#            input.physical_address,\n",
    "#            weight.physical_address,\n",
    "#            output.physical_address,\n",
    "#            wait_cycles)\n",
    "#     pt1 = time.perf_counter()\n",
    "#     time_sw = pt1 - pt0\n",
    "#     print(\"saa run time: %fs\" % time_sw)     \n",
    "    \n",
    "#     # 计算吞吐量\n",
    "    \n",
    "    \n",
    "#     return 0 \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
